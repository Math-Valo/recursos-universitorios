\begin{enunciado}
 Los siguientes datos muestran el n\'umero de defectos en 100,000 l\'{\i}neas de c\'odigo en un tipo particular de software hecho en Estados Unidos y Jap\'on.
 ¿Hay suficiente evidencia para afirmar que existe una diferencia significativa entre los programas de los dos pa\'{\i}ses?
 Pruebe las medias.
 ¿Deber\'{\i}an combinarse las varianzas?
 \begin{verbatim}
E.U.    48 39 42 52 40 48 52 52
        54 48 52 55 43 46 48 52
Japón   50 48 42 40 43 48 50 46
        38 38 36 40 40 48 48 45
 \end{verbatim}
 \vspace{-0.5cm}
\end{enunciado}

\begin{solucion}
 Para realizar una prueba de diferencia de medias con menos de 30 datos,
 se requiere la suposici\'on de que las muestras provengan de poblaciones
 con distribuci\'on normal.
 Para validar el uso de la prueba de dos medias, se realizar\'an pruebas
 de bondad de ajuste que indiquen si las muestras provienen de poblaciones
 normales.
 Entonces, la hip\'otesis nula para estas pruebas se pueden
 escribir de la forma: $X_i$ sigue una distribuci\'on normal,
 para cada $i \in \{1,2\}$, contra la hip\'otesis alternativa
 de que $X_i$, para cada $i \in \{1,2\}$, no sigue una distribuci\'on
 normal, donde $X_1$ y $X_2$ representan el n\'umero de defectos
 en $100,000$ l\'{\i}neas de c\'odigo en el software hecho en Estados
 Unidos y en Jap\'on, respectivamente.
 \par 
 Debido a que la muestra es peque\~na y no se consideran par\'ametros
 en la suposici\'on de las normalidades,
 la prueba con $\chi^2$ crea insuficientes clases, en cada muestra,
 que al calcular los grados de libertad junto con los grados que se restan
 por no considerar par\'ametros previos, entonces se obtiene
 un valor negativo, lo cual no puede corresponder a grados de libertad.
 Por lo tanto, se proceder\'a a realizar las pruebas de Geary,
 simult\'aneamente, con las siguientes l\'{\i}neas de c\'odigo
 escritas en R, que usa la base de datos
 \texttt{DB45\_Problema\_114.csv},
 que se presenta a continuaci\'on junto con los resultados:
 \begin{verbatim}
> datos<-read.csv("DB45_Problema_114.csv",sep=";",encoding="UTF-8")
> varInteres<-"Errores.PKLineas"; distincion<-"País"
> lista<-split(datos[,varInteres],datos[,distincion])
> x<-lista$EE.UU.; y<-lista$Japón
> n1<-length(x); n2<-length(y)
> U1<-sqrt(pi/2)*mean(abs(x-mean(x)))/sqrt(var(x)*(n1-1)/n1)
> U2<-sqrt(pi/2)*mean(abs(y-mean(y)))/sqrt(var(y)*(n2-1)/n2)
> x.Geary.statistic<-(U1-1)/(0.2661/sqrt(n1))
> y.Geary.statistic<-(U2-1)/(0.2661/sqrt(n2))
> x.Geary.p.value<-2*pnorm(abs(x.Geary.statistic),lower.tail=FALSE)
> y.Geary.p.value<-2*pnorm(abs(y.Geary.statistic),lower.tail=FALSE)
> print("P-valor para los errores en EE.UU. usando la prueba de Geary")
[1] "P-valor para los errores en EE.UU. usando la prueba de Geary"
> x.Geary.p.value
[1] 0.6938
> print("P-valor para los errores en Japón usando la prueba de Geary")
[1] "P-valor para los errores en Japón usando la prueba de Geary"
> y.Geary.p.value
[1] 0.03519627
 \end{verbatim}
 \vspace{-0.5cm}
 Esto indica un buen ajuste a una distribuci\'on normal
 para los datos correspondientes a EE.UU.;
 sin embargo, la poblaci\'on para los datos correspondientes a Jap\'on
 muestran un valor $P$ de $0.03519627$ para el ajuste de bondad.
 Se asumir\'a el riesgo ante la baja probabilidad
 y se tomar\'a la decisi\'on de suponer que ambas muestras vienen
 de poblaciones con distribuciones normales.
 Esto debido a que la prueba $t$ es relativamente robusta
 para la normalidad.
 Por otro lado, aunque la prueba de varianzas que se ver\'a
 a continuaci\'on no es robusta para la normalidad,
 se adelanta que se obtendr\'a un valor $P$ tan alto para dicha prueba
 que se podr\'a suponer sin mucho riesgo que las varianzas poblacionales
 son iguales.
 \par
 Para la prueba $t$, se requiere decidir tambi\'en si se va a suponer
 que las varianzas poblacionales de donde vienen ambas muestras
 son iguales o diferentes.
 Este lleva al an\'alisis a una prueba de proporci\'on de varianzas,
 cuya hip\'otesis nula se puede enunciar como
 $H_0: \, \sigma_1 = \sigma_2$, contra la hip\'otesis alternativa
 $H_1: \, \sigma_1 \neq \sigma_2$, donde $\sigma_1$ y $\sigma_2$
 representan las varianzas poblacionales de $X_1$ y $X_2$,
 respectivamente.
 Para ello se hace una prueba $F$ con ayuda del archivo adjunto
 \texttt{P14\_Prueba\_de\_dos\_varianzas\_02.r},
 que a su vez usa el archivo \texttt{DB45\_Problema\_114.csv},
 con los siguientes cambios:
 \begin{verbatim}
> datos<-read.csv("DB45_Problema_114.csv",sep=";",encoding="UTF-8")
> varInteres<-c("Errores.PKLineas")
> varSel<-c("País")
> alfa<-NULL
> cola<-'D'
 \end{verbatim}
 \vspace{-0.5cm}
 lo cual arroja el siguiente resultado:
 \begin{verbatim}
          variable Freq n1 n2  media1 media2 varianza1 varianza2 v1 v2 alpha
1 Errores.PKLineas   32 16 16 48.1875  43.75   24.9625  21.93333 15 15  0.05
     PValor Estadistico             RegionRechazo
1 0.8054528    1.138108 < 0.3493947 y > 2.8620925
 \end{verbatim}
 \vspace{-0.5cm}
 en donde se observa que el estad\'{\i}stico $F=\frac{\sigma_1}{\sigma_2}$
 toma el valor de $1.138108$ con $v_1 = v_2 = 15$ grados
 de libertad para la distribuci\'on $F$,
 obteniendo as\'{\i} un valor $P$ de $0.8054528$,
 lo cual, al ser muy alto, no se rechaza la hip\'otesis nula y,
 por lo tanto, se puede suponer las varianzas iguales para la prueba $t$.
 \par 
 Para la prueba que concierne a la pregunta planteada en el problema,
 se enuncia la hip\'otesis nula como sigue:
 \begin{eqnarray*}
  H_0: & & \mu_1 - \mu_2   =  0 \\
  H_1: & & \mu_1 - \mu_2 \neq 0
 \end{eqnarray*}
 donde $\mu_1$ y $\mu_2$ representan las medias poblacionales
 de $X_1$ y $X_2$, respectivamente.
 El estad\'{\i}stico y el valor $P$ se calculan con ayuda
 del archivo adjunto \texttt{P06\_Prueba\_de\_dos\_medias\_02.r},
 que nuevamente usa la base de datos almacenado en el archivo adjunto
 \texttt{DB45\_Problema\_114.csv}, con los siguientes cambios:
 \begin{verbatim}
> datos<-read.csv("DB45_Problema_114.csv",sep=";",encoding="UTF-8")
> varInteres<-c("Errores.PKLineas")
> varSel<-c("País")
> mu<-0
> desv.iguales<-TRUE
> alfa<-NULL
> cola<-'D'
> par<-FALSE
 \end{verbatim}
 \vspace{-0.5cm}
 lo cual arroja el siguiente resultado:
 \begin{verbatim}
              Var1 Freq    Poblaciones H0 valorPVar     suposicionVar n1 n2
1 Errores.PKLineas   32 Independientes  0 0.8054528 Var no diferentes 16 16
   media1 media2 diferencia desv.est1 desv.est2   est.sp error.est grados alpha
1 48.1875  43.75     4.4375  4.996249  4.683304 4.842305  1.712013     30  0.05
      PValor Estadistico RegionRechazoInfT RegionRechazoSupT RegionRechazoInfX
1 0.01460178    2.591978         -2.042273          2.042273         -3.496398
  RegionRechazoSupX
1          3.496398
 \end{verbatim}
 \vspace{-0.5cm}
 de donde se observa que el estad\'{\i}stico obtenido es $t = 2.591978$,
 con $v = n_1 + n_2 - 2 = 30$ grados de libertad para la distribuci\'on
 $t$, lo que corresponde a un valor $P$ de $0.01460178$,
 que corresponde a un valor $P$ muy bajo.
 Considerando adem\'as que la prueba es de 2 colas
 y que $\bar{x}_1 = 48.1875$ y $\bar{x}_2 = 43.75$,
 donde las pruebas de dos colas no se consideran tan estrictas,
 por lo que el valor $P$ habr\'{\i}a sido menor para una prueba
 de cola superior, la decisi\'on tomada es rechazara $H_0$
 a favor de $H_1$ y, por lo tanto, concluir que hay evidencia suficiente
 para afirmar que hay una diferencia significativa entre los programas
 de ambos pa\'{\i}ses, siendo el programa de Jap\'on
 el que presenta menos errores por cada mil l\'{\i}neas de c\'odigo,
 que es a lo que se quer\'{\i}a llegar.${}_{\blacksquare}$
\end{solucion}
